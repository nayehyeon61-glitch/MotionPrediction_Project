import copy
from json import load
import json
from types import SimpleNamespace
import time 
from multiprocessing import Condition
import os
from random import randint, random
import sys
import platform
import pdb
from unittest import loader
from xml.dom import minicompat # use pdb.set_trace() for debugging
sys.path.append(os.getcwd())
import libmainlib as m   
import luamodule as lua  # see luamodule.py
import numpy as np 
import torch 
from gym_mp.models2 import Encoder,Decoder,VAE, VQVAE,DenoiseDiffusion14
import torch.optim as optim
from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler , RandomSampler
from tensorboardX import SummaryWriter 
import torch.nn.functional as F 
import settings
# ensure model available when called from Lua without running main()
def _ensure_dif_model_loaded():
    if not hasattr(settings, 'DIF1016') or settings.DIF1016 is None:
        with open("config/dif_pose_vec.json", "r") as file:
            cfg = json.load(file)
        pt_path = cfg["path"]["pt_path"] + cfg["model"]["pt_name"] + ".pt"
        try:
            settings.DIF1016 = torch.load(pt_path, map_location=torch.device("cpu"))
            settings.DIF1016.eval()
        except Exception as e:
            print(f"failed to load model: {pt_path} ({e})")
            raise
# simply forward UI events to lua
def onCallback(mid, userdata):
    lua.onCallback(mid, userdata)

def onFrameChanged(currFrame):
    lua.onFrameChanged(currFrame)

def frameMove(fElapsedTime):
    lua.frameMove(fElapsedTime)

def handleRendererEvent(ev, button, x,y):
    return lua.handleRendererEvent(ev, button, x,y)

def lua_getdim():
    l=m.getPythonWin()
    l.getglobal("get_dim")
    l.call(0,1)
    info= l.popvectorn()
    state_dim=int(info.get(0))
    action_dim=int(info.get(1))
    # print(state_dim)
    # print(action_dim)
    return state_dim,action_dim

def lua_getIframe(iframe):
    l=m.getPythonWin()
    l.getglobal("seok_getIframeDOF")
    input = m.vectorn()
    input.setSize(0)
    input = iframe
    # print(input)
    l.push(input)
    l.call(1,1)
    return l.popvectorn()

def lua_getFrame():
    l = m.getPythonWin()
    l.getglobal("get_frame")
    l.call(0,1)
    return l.popnumber()

def Tonumpy(data):
    return np.array(data.ref())

def Discontinuity():
    l = m.getPythonWin()
    l.getglobal("getDiscontinuity")
    l.call(0,1)
    return l.popvectorn()

def Alldata_load():
    l=m.getPythonWin()
    l.getglobal("All_data_frames")
    l.call(0,1)
    return l.popmatrixn()

def main():
    
    with open("config/dif_pose_vec.json", "r") as file:
        config = json.load(file)
    
    train = True
    
    load_save_model = False
    latent_size = config["train_parameter"]["latent_size"]
    #walk : 64~128 stitch:512~1024
    mini_batch = config["train_parameter"]["mini_batch"]
    teacher_epochs = config["train_parameter"]["teacher_epochs"]
    ramping_epochs = config["train_parameter"]["ramping_epochs"]
    student_epochs = config["train_parameter"]["student_epochs"]
    num_epochs = teacher_epochs+ramping_epochs+student_epochs
    num_experts = config["train_parameter"]["num_experts"]
    input_frames = config["model"]["input_frames"]
    initial_lr = config["train_parameter"]["initial_lr"]
    # final_lr = 1e-7
    prediction_frames = config["train_parameter"]["recursive_frames"]
    condition_frame = config["train_parameter"]["condition_frames"]
    hidden_dim = config["train_parameter"]["hidden_dim"]
    codebook_size = config["train_parameter"]["code_dim"]
    beta = config["train_parameter"]["beta"]
    pt_path = config["path"]["pt_path"] + config["model"]["pt_name"] + ".pt"
    timestep = config["train_parameter"]["time_steps"]
    option=''
    if len(sys.argv)==1:
        scriptFile = config["path"]["lua_path"]
    elif len(sys.argv)==2:
        scriptFile=config["path"]["lua_path"]
        if sys.argv[1] == 'False':
            train = False
            settings.train = False
        else :
            train = True
            settings.train = True
    elif len(sys.argv)==3:
        option=sys.argv[1]
        scriptFile=sys.argv[2] 
    uiscale=1.5
    
    if train :
        device =torch.device("cpu")
        #device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device("cpu")
        
    if option=='--sep':
        if platform.system()=='Darwin':
            m.createMainWin(int((10+220)*uiscale),int((400+100)*uiscale), int(10*uiscale), int(400*uiscale),uiscale, "../Resource/ogreconfig_linux_sepwin.txt", "plugins_mac.cfg", "ogre_mac.cfg")
        else:
            m.createMainWin(int((10+220)*uiscale),int((400+100)*uiscale), int(10*uiscale), int(400*uiscale),uiscale, "../Resource/ogreconfig_linux_sepwin.txt", "plugins_linux.cfg", "ogre_linux.cfg")
    else:
        m.createMainWin(int((1024+180)*uiscale),int((600+100)*uiscale), int(1024*uiscale), int(600*uiscale),uiscale)
    m.showMainWin()
    if scriptFile[0:1]!='.':
        scriptFile=os.path.relpath(scriptFile, os.getcwd())
    if scriptFile[-3:]!='lua':
        scriptFile=scriptFile+'.lua'
    l=m.getPythonWin()

    print('loading', scriptFile)
    #loadScrit == ctor 까지 수행됨
    l.loadScript(scriptFile)
    # mode_setting function
    # python에서 argument, return 받아오는 법
    # getglobal ("함수 이름")
    l.getglobal('mode_setting')
    # push (넣으려고 하는 parameter "스택"형식으로 쌓기)
    l.push(settings.train)
    # call로 불러 오면서 return (앞이 인자개수, 리턴 개수)
    l.call(1,0)
    # 써진 반대로 (스택이니까) pop! 

    mocap_data = torch.from_numpy(Tonumpy(Alldata_load())).float().to(device)
    if torch.isnan(mocap_data).any():
        print("mocap data has nan value")

    discont = Tonumpy(Discontinuity())
    discont = list(map(int,discont))
    mocap_size = mocap_data.shape[0] #numframes = 26909
    frame_size = mocap_data.shape[1] #frame_size = 35
    input_size = frame_size
    output_size = frame_size


    ######data normalize##########
    avg = mocap_data.mean(dim=0)
    std = mocap_data.std(dim=0)
    for i in range(len(std)):
        if std[i] == 0:
            std[i] = 1
    mocap_data = (mocap_data-avg)/std
    ##############################
    #vqvae = VQVAE(input_size,hidden_dim, latent_size, output_size, codebook_size, latent_size, beta, False, input_frames, num_experts, True, False).to(device)
    #vqvae.set_normalization(std.to(device="cpu"),avg.to(device="cpu"))
    vqvae = DenoiseDiffusion14(input_size,timestep,latent_size,output_size).to(device)
    if load_save_model :
        print("loading model")
        vqvae = torch.load("vqvae_model_10_large_to_one.pt",map_location=device)

    vqvae.train()
    vqvae_optimizer = optim.Adam(vqvae.parameters(),lr=initial_lr)
    scheduler_lr = optim.lr_scheduler.StepLR(vqvae_optimizer,step_size=10,gamma=0.9)
    writer = SummaryWriter(comment="MVQVAE"+"\nenv_name" + scriptFile + "\nbatch size"+str(num_epochs) + "\nmini batch size" + str(mini_batch) + "\nlearning rate"+str(vqvae_optimizer.param_groups[0]['lr']))
    all_indices = np.linspace(0,mocap_size-1,mocap_size)
    bad_indices = []
    for i in range(len(discont)-1):
        for j in range(12):
            bad_indices.append(discont[i+1] - j)
    bad_indices.sort()
    good_mask = np.isin(all_indices,bad_indices,assume_unique=True,invert=True)
    selectable_indices = all_indices[good_mask]
    sample_schedule = torch.cat(
    (
        # First part is pure teacher forcing
        torch.zeros(teacher_epochs),
        # Second part with schedule sampling
        torch.linspace(0.0,1.0,ramping_epochs),
        # last part is pure student
        torch.ones(student_epochs),
    ))
    
    print(selectable_indices)
    if train:
        shape = (mini_batch,condition_frame,output_size)
        input_shape = (mini_batch,input_frames,output_size)
        history = torch.empty(shape).to(device)
        encode_buffer = torch.empty(input_shape).to(device)
        
        start = time.time()
        
        for ep in range(1,num_epochs+1):
            sampler = BatchSampler(SubsetRandomSampler(selectable_indices),mini_batch,drop_last=True)
            ep_recon_loss = 0
            ep_q_loss = 0
            ep_noise_loss =0
            num_of_minibatch = 1  
            
            for num_of_minibatch,indices in enumerate(sampler):
                t_indices = torch.LongTensor(indices)

                t_indices += 1 
                condition_range = (
                t_indices.repeat((1, 1)).t()
                + torch.arange(0, -1, -1).long()
                )
                history[:,:1].copy_(mocap_data[condition_range])
                in_range =condition_range
                
                                         
                
                for offset in range(1,prediction_frames):
                    use_student = torch.rand(1) < sample_schedule[ep - 1]
                    prediction_range = (
                            t_indices.repeat((1, 1)).t()
                            + torch.arange(offset, offset + 1).long()
                        )
                    t = torch.randint(0, timestep, (mini_batch, input_size,), device=device).long()
                    ground_truth = mocap_data[prediction_range]
                    condition = history[:, :1]
                    condition = condition.flatten(start_dim=1, end_dim=2)
                    ground_truth = ground_truth.flatten(start_dim=1, end_dim=2)
                    
                    curr_pose = mocap_data[t_indices]
                   
                    curr_pose_vec = ground_truth - curr_pose
                   
                    noise = torch.randn_like(curr_pose_vec)
                    curr_pose_noise = vqvae.q_sample(curr_pose_vec, t, noise)
                    ground_noise = vqvae.q_sample(ground_truth,t,noise)
                    
                    condition_noise = vqvae.q_sample(condition, t)
                    
                    output, mu , logvar =vqvae(curr_pose_noise,t,condition)
                    curr_pose_n = vqvae.p_sample(curr_pose, t, condition)
                    
                    
                    history = history.roll(1,dims=1)

                    next_frame = output if use_student else ground_truth
                
                    
                    history[:,0].copy_(next_frame.detach())
                    recon_loss = (output - noise).pow(2).mean(dim=(0,-1))
                    recon_loss = recon_loss.sum()
    
                    recon_loss2 = (curr_pose_n-ground_truth).pow(2).mean(dim=(0,-1))
                    recon_loss2 = recon_loss2.sum()

                    loss = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).sum().clamp(max=0)
                    loss /= logvar.numel()
                    vqvae_optimizer.zero_grad()
                    #(recon_loss+loss).backward()
                    (recon_loss+loss+recon_loss2).backward()
                    vqvae_optimizer.step()
                    
                    ep_q_loss += float(loss)/prediction_frames
                    ep_recon_loss += float(recon_loss) / prediction_frames
                    ep_noise_loss += float(recon_loss2) / prediction_frames
                   
            avg_recon_loss = ep_recon_loss / mini_batch
            avg_kl_loss = ep_q_loss / mini_batch
            avg_noise_loss = ep_noise_loss / mini_batch
            scheduler_lr.step()
            end = time.time()

            print("epoch : {ep}, ep_noise_loss : {ep_recon_loss:0.08f},kl_loss : {q:0.08f}, ep_noise2_loss:{ep_noise2_loss:0.08f} learning_rate : {lr:0.07f} , FPS : {FPS}".format(ep=ep,ep_recon_loss=avg_recon_loss,q=ep_q_loss,ep_noise2_loss=avg_noise_loss,lr=vqvae_optimizer.param_groups[0]['lr'],FPS=int((ep/(end-start))*100)))
            writer.add_scalar('ep_noise_loss',avg_recon_loss,ep)
            writer.add_scalar('ep_kl_loss',avg_kl_loss,ep)
            writer.add_scalar('ep_recon2_loss',avg_recon_loss,ep)
            writer.add_scalar('learning_rate',vqvae_optimizer.param_groups[0]['lr'],ep)
            writer.add_scalar('ep_noise2_loss',avg_noise_loss,ep)
            torch.save(copy.deepcopy(vqvae).cpu(), pt_path)
    else:
        settings.DIF1016 = torch.load(pt_path)
        m.startMainLoop()
        
def getTrain(flag):
    if settings.train == True:
        tmp = np.array([1])
        flag.ref()[:] = tmp
    else:
        tmp = np.array([0])
        flag.ref()[:] = tmp
        
        
    return flag


    
    
def test_dif16(latent,condition_l,latent2,vae_output):
    with torch.no_grad():
        settings.DIF1016.eval()
        latent_vector = torch.tensor(Tonumpy(latent)).float()
        condition = torch.tensor(Tonumpy(condition_l)).float()
        latent_vector2=torch.tensor(Tonumpy(latent2)).long()
        latent_vector2=latent_vector2.view(1,-1)
        latent_vector=latent_vector.view(1,-1)
        condition=condition.view(1,-1)
        
        output = settings.DIF1016.p_sample(condition, latent_vector2, condition)
        output = output.detach().numpy()
        vae_output.ref()[:] = output
        return vae_output
def test_dif316(latent,latent2,latent3,latent4,latent5,latent6,latent7,latent8,latent9,condition_l,latent0,vae_output):
    with torch.no_grad():
        _ensure_dif_model_loaded()
        settings.DIF1016.eval()
        latent_vector = torch.tensor(Tonumpy(latent)).float()
        latent_vector2 = torch.tensor(Tonumpy(latent2)).float()
        latent_vector3 = torch.tensor(Tonumpy(latent3)).float()
        latent_vector4 = torch.tensor(Tonumpy(latent4)).float()
        latent_vector5 = torch.tensor(Tonumpy(latent5)).float()
        latent_vector6 = torch.tensor(Tonumpy(latent6)).float()
        latent_vector7 = torch.tensor(Tonumpy(latent7)).float()
        latent_vector8 = torch.tensor(Tonumpy(latent8)).float()
        latent_vector9 = torch.tensor(Tonumpy(latent9)).float()
        
        condition = torch.tensor(Tonumpy(condition_l)).float()
        latent_vector0=torch.tensor(Tonumpy(latent0)).long()
        latent_vector0=latent_vector0.view(1,-1)
        latent_vector=latent_vector.view(1,-1)
        latent_vector2=latent_vector2.view(1,-1)
        latent_vector3=latent_vector3.view(1,-1)
        latent_vector4=latent_vector4.view(1,-1)
        latent_vector5=latent_vector5.view(1,-1)
        latent_vector6=latent_vector6.view(1,-1)
        latent_vector7=latent_vector7.view(1,-1)
        latent_vector8=latent_vector8.view(1,-1)
        latent_vector9=latent_vector9.view(1,-1)
       
        condition=condition.view(1,-1)
    
        output = settings.DIF1016.p_sample(latent_vector, latent_vector0, latent_vector)     
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector5)
        output = settings.DIF1016.p_sample(output,latent_vector0,condition)
        
        output = output.detach().numpy()
        vae_output.ref()[:] = output
        return vae_output
def test_dif516(latent,latent2,latent3,latent4,latent5,latent6,latent7,latent8,latent9,condition_l,latent0,vae_output):
    with torch.no_grad():
        _ensure_dif_model_loaded()
        settings.DIF1016.eval()
        latent_vector = torch.tensor(Tonumpy(latent)).float()
        latent_vector2 = torch.tensor(Tonumpy(latent2)).float()
        latent_vector3 = torch.tensor(Tonumpy(latent3)).float()
        latent_vector4 = torch.tensor(Tonumpy(latent4)).float()
        latent_vector5 = torch.tensor(Tonumpy(latent5)).float()
        latent_vector6 = torch.tensor(Tonumpy(latent6)).float()
        latent_vector7 = torch.tensor(Tonumpy(latent7)).float()
        latent_vector8 = torch.tensor(Tonumpy(latent8)).float()
        latent_vector9 = torch.tensor(Tonumpy(latent9)).float()
        
        condition = torch.tensor(Tonumpy(condition_l)).float()
        #condition_1 = torch.tensor(Tonumpy(condition_l)).long()
        #condition = settings.DIF10.q_sample(condition,0)
        latent_vector0=torch.tensor(Tonumpy(latent0)).long()
        latent_vector0=latent_vector0.view(1,-1)
        latent_vector=latent_vector.view(1,-1)
        latent_vector2=latent_vector2.view(1,-1)
        latent_vector3=latent_vector3.view(1,-1)
        latent_vector4=latent_vector4.view(1,-1)
        latent_vector5=latent_vector5.view(1,-1)
        latent_vector6=latent_vector6.view(1,-1)
        latent_vector7=latent_vector7.view(1,-1)
        latent_vector8=latent_vector8.view(1,-1)
        latent_vector9=latent_vector9.view(1,-1)
       
        condition=condition.view(1,-1) 
        output = settings.DIF1016.p_sample(condition,latent_vector0,condition)
        output = settings.DIF1016.p_sample(output,latent_vector0,condition)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector9)
        output = settings.DIF1016.p_sample(output,latent_vector0,condition)
        
        output = output.detach().numpy()
        vae_output.ref()[:] = output
        #print(vae_output.shape)
        return vae_output
def test_dif1016(latent,latent2,latent3,latent4,latent5,latent6,latent7,latent8,latent9,condition_l,latent0,vae_output):
    with torch.no_grad():
        _ensure_dif_model_loaded()
        settings.DIF1016.eval()
        latent_vector = torch.tensor(Tonumpy(latent)).float()
        latent_vector2 = torch.tensor(Tonumpy(latent2)).float()
        latent_vector3 = torch.tensor(Tonumpy(latent3)).float()
        latent_vector4 = torch.tensor(Tonumpy(latent4)).float()
        latent_vector5 = torch.tensor(Tonumpy(latent5)).float()
        latent_vector6 = torch.tensor(Tonumpy(latent6)).float()
        latent_vector7 = torch.tensor(Tonumpy(latent7)).float()
        latent_vector8 = torch.tensor(Tonumpy(latent8)).float()
        latent_vector9 = torch.tensor(Tonumpy(latent9)).float()
        
        condition = torch.tensor(Tonumpy(condition_l)).float()
        #condition_1 = torch.tensor(Tonumpy(condition_l)).long()
        #condition = settings.DIF10.q_sample(condition,0)
        latent_vector0=torch.tensor(Tonumpy(latent0)).long()
        latent_vector0=latent_vector0.view(1,-1)
        latent_vector=latent_vector.view(1,-1)
        latent_vector2=latent_vector2.view(1,-1)
        latent_vector3=latent_vector3.view(1,-1)
        latent_vector4=latent_vector4.view(1,-1)
        latent_vector5=latent_vector5.view(1,-1)
        latent_vector6=latent_vector6.view(1,-1)
        latent_vector7=latent_vector7.view(1,-1)
        latent_vector8=latent_vector8.view(1,-1)
        latent_vector9=latent_vector9.view(1,-1)
       
        condition=condition.view(1,-1)
       
        output = settings.DIF1016.p_sample(latent_vector, latent_vector0, condition)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector2)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector3)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector4)
        output = settings.DIF1016.p_sample(output, latent_vector0,latent_vector5)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector6)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector7)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector8)
        output = settings.DIF1016.p_sample(output, latent_vector0, latent_vector9)
        output = settings.DIF1016.p_sample(output,latent_vector0,condition)
        
        output = output.detach().numpy()
        vae_output.ref()[:] = output
      
        return vae_output

if __name__=="__main__":
    main()
